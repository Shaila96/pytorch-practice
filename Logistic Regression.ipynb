{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Basics\n",
    "\n",
    "This is a classification algorithm.\n",
    "\n",
    "###### Basic Comparison\n",
    "- Linear Regression\n",
    "    - Output: numeric value given inputs\n",
    "- Logistic Regression\n",
    "    - Output: probability [0, 1] given input belonging to a class\n",
    "    - Logistic regression is an extension of linear regression, with additional\n",
    "        - Softmax function\n",
    "        - Cross entropy function instead of MSE function\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "###### Logistic Function g()\n",
    "- Two-class logistic regression\n",
    "\n",
    "###### Softmax Function g()\n",
    "- Multi-class logistic regression\n",
    "- Generalization of logistic fuction\n",
    "\n",
    "###### Cross Entropy Function D()\n",
    "- D(S, L)=LlogS - (1-L)log(1-S)\n",
    "    - S = g(y) = g(ax+b)\n",
    "    - L = label (0 or 1)\n",
    "    \n",
    "###### Cross Entropy Loss (L)\n",
    "- Goal: Minimizing Cross Entropy Loss\n",
    "\n",
    "\n",
    "\n",
    "###### Watch video 22. Linear Regression Problems \n",
    "### ***Watch video 23. Logistic Regression In-depth to understand the concept better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Steps:\n",
    "- Step 1: Load dataset\n",
    "- Step 2: Make dataset iterable\n",
    "- Step 3: Create model class\n",
    "- Step 4: Instantiate model class\n",
    "- Step 5: Instantiate loss class\n",
    "- Step 6: Instantiate optimizer class\n",
    "- Step 7: Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST Train Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch            ## for creating tensors\n",
    "import torch.nn as nn   ## for modeling\n",
    "import torchvision.transforms as transforms    ## make data iterable\n",
    "import torchvision.datasets as dsets           ## make data iterable\n",
    "\n",
    "\n",
    "from torch.autograd import Variable  ## make variable for enable gradients\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data loading\n",
    "- transforming to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dsets.MNIST(root='./data',\n",
    "                      train=True,\n",
    "                      transform=transforms.ToTensor(),\n",
    "                      download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.MNIST'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(train_df))\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]), 5)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df[0]) ## first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Input matrix\n",
    "## This is actually the feature\n",
    "type(train_df[0][0]) ## 1st element in 1st row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Label\n",
    "type(train_df[0][1]) ## 2nd element in 1st row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[2][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## coverting torch obj. to numpy obj.\n",
    "train_df[0][0].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_df[0][0].numpy().reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12155d7b8>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x122749198>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = train_df[2][0].numpy().reshape(28, 28)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[2][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading MNIST Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = dsets.MNIST(root='./data',\n",
    "                      train=False,\n",
    "                      transform=transforms.ToTensor(),\n",
    "                      download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12160cf60>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = test_df[2][0].numpy().reshape(28, 28)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[2][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Make Dataset Iterable\n",
    "\n",
    "- **Aim:** make the dataset iterable\n",
    "- **total data:** 60000\n",
    "- **mini-batch:** 100\n",
    "    - Number of examples in 1 iteration\n",
    "    - Passing 100 images instead of passing 1 image\n",
    "    - This is for efficiency purposes\n",
    "- **iterations:** 3000\n",
    "    - 1 iteration: one mini-batch forward & backward pass\n",
    "    - forward pass: \n",
    "        - passing 100 images\n",
    "        - get the predictions\n",
    "    - backward pass:\n",
    "        - get the gradients\n",
    "        - update the parameters\n",
    "- **epochs:** \n",
    "    - 1 epoch: running through the whole dataset(60000) once\n",
    "    - 5 epochs: running through the whole dataset(60000) 5 times\n",
    "    - $epochs = iterations \\div \\frac{totaldata}{mini-batch} = 3000 \\div \\frac{60000}{100} = 5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "\n",
    "n_epochs = int(n_iters / (len(train_df) / batch_size))\n",
    "n_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Iterable Object: Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_df,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Iterability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "\n",
    "isinstance(train_loader, collections.Iterable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Iterable Object: Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_df,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "isinstance(test_loader, collections.Iterable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main aim: Iterate Through Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "img_1 = np.ones((28, 28))\n",
    "img_2 = np.ones((28, 28))\n",
    "\n",
    "img_list = [img_1, img_2]\n",
    "\n",
    "\n",
    "for img in img_list:\n",
    "    print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as linear regression!! :D\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Instantiate Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "\n",
    "model = LogisticRegressionModel(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Instantiate Loss Class\n",
    "- Logistic Regression\n",
    "    - Cross Entropy Function\n",
    "    - Output is probability of each specified prediction\n",
    " \n",
    "- Linear Regression\n",
    "    - Mean Squared Error Function\n",
    "    - Output is value prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What happens in nn.CrossEntropyLoss()\n",
    "- Computes softmax (logistic/softmax function)\n",
    "- Computes cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Instantiate Optimizer Class\n",
    "- parameters = parameters - learning_rate * parameters_gradients\n",
    "- **At every iteration, we update our model's parameters**\n",
    "\n",
    "\n",
    "###### What is the purpose fo the optimizer class\n",
    "- Update the model's parameter at every iteration\n",
    "- So that, we can get a better model to do the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters In-Depth\n",
    "- For more clarification watch the video no 24 (20-30min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x12140bed0>\n",
      "2\n",
      "torch.Size([10, 784])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters())\n",
    "\n",
    "print(len(list(model.parameters())))\n",
    "\n",
    "\n",
    "# y = Ax + b\n",
    "# This is A or Alpha\n",
    "print(list(model.parameters())[0].size())\n",
    "\n",
    "\n",
    "# y = Ax + b\n",
    "# This is B or Bias\n",
    "print(list(model.parameters())[1].size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 1.848568081855774. Accuracy: 67.\n",
      "Iteration: 1000. Loss: 1.6495128870010376. Accuracy: 74.\n",
      "Iteration: 1500. Loss: 1.3659979104995728. Accuracy: 78.\n",
      "Iteration: 2000. Loss: 1.2253953218460083. Accuracy: 80.\n",
      "Iteration: 2500. Loss: 1.1608725786209106. Accuracy: 81.\n",
      "Iteration: 3000. Loss: 1.0317223072052002. Accuracy: 82.\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "\n",
    "for epoch in range(n_epochs): ## this loop will go through all 60,000 images 5 times\n",
    "    for idx, (images, labels) in enumerate(train_loader): ## this loop will go through all 60,000 images once\n",
    "        # Load images as Variable\n",
    "        images = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameter\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calcultae Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #Calculate gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter%500==0:\n",
    "            # Calculate accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            # Iterate through the test dataset\n",
    "            for images, labels in test_loader:\n",
    "                \n",
    "                # Load images to a Torch Variable\n",
    "                images = Variable(images.view(-1, 28*28))\n",
    "                \n",
    "                # Forward pass only the to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of lables\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            # Print loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}.'.format(iter, loss.data, accuracy))\n",
    "                \n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Break Down Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs\n",
      "tensor([[-3.9149e-01, -1.0796e+00, -4.6823e-01, -3.3329e-01,  1.1494e-01,\n",
      "         -2.2923e-01, -1.3685e+00,  2.8098e+00, -6.9628e-02,  9.8259e-01],\n",
      "        [ 3.4675e-01,  6.2777e-02,  1.7298e+00,  1.0837e+00, -1.8653e+00,\n",
      "          7.9923e-01,  1.0147e+00, -1.8861e+00,  5.1618e-01, -1.5674e+00],\n",
      "        [-9.7693e-01,  2.2633e+00,  1.4710e-01, -1.5660e-02, -8.6012e-01,\n",
      "         -3.0272e-01, -1.5734e-01, -1.8561e-01,  8.9228e-02, -3.1040e-01],\n",
      "        [ 2.7756e+00, -2.3442e+00, -1.1371e-01, -4.0263e-01, -8.7945e-01,\n",
      "          6.8145e-01,  9.4555e-01,  2.6862e-01, -4.4036e-01, -3.3591e-01],\n",
      "        [-7.2493e-02, -1.9168e+00,  1.8537e-01, -7.1404e-01,  1.6804e+00,\n",
      "         -3.8898e-01,  1.5236e-01,  4.5282e-01, -1.1116e-01,  8.3815e-01],\n",
      "        [-1.3487e+00,  2.8005e+00,  5.7745e-02,  1.0180e-01, -8.4645e-01,\n",
      "         -3.7220e-01, -6.3281e-01, -5.7424e-02,  4.1136e-01, -1.5824e-01],\n",
      "        [-1.2969e+00, -1.1406e+00, -6.6221e-01,  9.2530e-02,  1.5105e+00,\n",
      "          3.4380e-01, -7.3622e-01,  7.8511e-01,  5.4135e-01,  1.0918e+00],\n",
      "        [-1.2567e+00, -4.0685e-01, -6.0875e-01,  3.5715e-02,  8.0294e-01,\n",
      "          2.7051e-01,  2.5141e-01, -1.1867e-01,  6.0981e-02,  1.1739e+00],\n",
      "        [ 2.8018e-01, -4.4145e-01,  8.1905e-01, -1.2744e+00,  3.3660e-01,\n",
      "          1.8115e-01,  9.8449e-01, -6.4294e-01,  4.1889e-02, -2.7339e-02],\n",
      "        [-4.5552e-01, -8.9452e-01, -1.1680e+00, -1.1962e+00,  1.1528e+00,\n",
      "         -2.4864e-01, -4.5041e-01,  1.8469e+00,  2.4246e-01,  1.9567e+00],\n",
      "        [ 3.2954e+00, -1.9635e+00,  4.5745e-01,  1.0705e+00, -8.5803e-01,\n",
      "          1.0671e+00, -3.1706e-01, -1.2571e+00,  6.1481e-01, -1.5777e+00],\n",
      "        [ 7.3894e-01, -4.4627e-01,  5.0318e-01, -4.3325e-02,  2.7333e-01,\n",
      "         -2.8471e-01,  6.4951e-01, -8.1002e-01, -1.7053e-02, -6.2698e-01],\n",
      "        [-9.4288e-01, -1.4620e+00, -8.1564e-01, -1.0015e+00,  1.5516e+00,\n",
      "         -2.3928e-01, -2.9156e-01,  9.9179e-01,  2.8069e-01,  2.1013e+00],\n",
      "        [ 3.0048e+00, -2.4520e+00, -3.1009e-01, -1.7597e-01, -3.9541e-01,\n",
      "          5.7248e-01, -3.8816e-01, -6.8670e-01,  5.6715e-01,  6.4394e-02],\n",
      "        [-1.4120e+00,  2.8563e+00, -1.5179e-01,  3.5089e-01, -1.1580e+00,\n",
      "          2.3269e-02, -7.7739e-02, -1.1710e-01,  3.0643e-01, -9.5761e-02],\n",
      "        [ 5.6193e-01, -8.9336e-01,  4.7311e-02,  1.2568e+00, -4.0822e-01,\n",
      "          8.4493e-01, -2.4765e-01, -7.0313e-01,  7.4727e-01, -5.9613e-01],\n",
      "        [-5.3560e-01, -1.9014e+00,  1.2364e-03, -7.5815e-01,  1.3509e+00,\n",
      "         -5.4659e-01, -2.5241e-01,  9.0254e-01,  4.4352e-02,  1.7037e+00],\n",
      "        [ 2.2381e-01, -1.5985e+00, -6.6991e-01,  2.5538e-01, -4.4916e-03,\n",
      "         -1.7602e-01, -9.4548e-01,  2.7454e+00, -4.2193e-01,  5.3205e-01],\n",
      "        [-7.1506e-01, -4.0292e-01, -8.9865e-02,  1.0764e+00, -4.9181e-01,\n",
      "          6.4105e-01,  6.4199e-01, -7.7132e-01,  4.3740e-01, -2.2585e-01],\n",
      "        [-6.8435e-01, -1.5181e+00, -3.6858e-01, -2.8087e-01,  1.9258e+00,\n",
      "         -3.0579e-04,  4.3004e-03, -1.1926e-02,  5.5246e-02,  1.3698e+00],\n",
      "        [-9.7184e-01, -3.3914e-01, -1.2523e+00,  5.0783e-02,  6.3587e-01,\n",
      "          1.4163e-01, -1.3782e+00,  1.7251e+00,  3.8331e-01,  1.7103e+00],\n",
      "        [-5.2869e-01, -1.5134e+00,  1.4026e-01,  4.5502e-01,  4.8061e-01,\n",
      "          5.0403e-01,  2.2856e+00, -1.4390e+00,  3.1952e-01,  1.0851e-01],\n",
      "        [-3.7899e-01,  1.6004e-01,  2.7242e-01, -7.4685e-01,  6.4563e-01,\n",
      "         -9.0120e-01,  9.9393e-01, -1.0250e-01, -3.5397e-01, -9.0032e-02],\n",
      "        [ 9.7160e-02, -9.3294e-01, -6.2585e-01,  5.3787e-01, -1.7684e-01,\n",
      "          1.1519e+00,  4.3105e-01, -9.4365e-01,  9.3218e-01, -1.7635e-01],\n",
      "        [-7.0914e-01, -9.4886e-01, -5.4809e-02, -2.3657e-01,  1.2803e+00,\n",
      "         -2.9993e-01, -1.3769e-01,  4.2036e-01, -2.0146e-01,  1.0595e+00],\n",
      "        [ 4.1046e+00, -2.8249e+00,  4.8406e-01, -1.0939e+00, -1.6870e-01,\n",
      "          1.1912e+00,  1.2553e+00, -6.5815e-01,  2.9370e-02, -1.2277e+00],\n",
      "        [-3.1054e-01, -1.3799e+00, -5.7134e-01, -6.9860e-02,  4.2505e-01,\n",
      "         -2.4152e-02, -4.9126e-01,  1.8485e+00, -4.1975e-01,  1.0965e+00],\n",
      "        [-2.4707e-01, -2.1484e+00, -3.9336e-01, -7.4089e-01,  2.3601e+00,\n",
      "         -2.9570e-02,  2.4317e-01, -4.2946e-02,  8.3227e-03,  1.4078e+00],\n",
      "        [ 2.6868e+00, -2.2704e+00,  2.6255e-01,  1.0700e+00, -1.0052e+00,\n",
      "          8.0052e-01, -2.9397e-01, -7.0210e-01,  6.7951e-01, -7.3567e-01],\n",
      "        [-1.0846e+00,  1.4182e+00, -2.5673e-01,  2.0484e-01, -5.3269e-01,\n",
      "          3.1293e-01,  2.5939e-01,  3.4797e-02,  4.1161e-01, -1.5305e-01],\n",
      "        [-7.6718e-01,  2.2148e-02, -9.2019e-01,  2.3468e+00, -1.0971e+00,\n",
      "          9.3563e-01, -5.4696e-01,  5.4362e-01,  6.3045e-02,  2.3733e-01],\n",
      "        [-9.3791e-01,  1.0936e+00, -3.1048e-01,  3.9162e-01, -3.5293e-01,\n",
      "          1.4932e-01, -1.0555e-01,  9.6545e-02,  1.2053e-01,  2.4354e-01],\n",
      "        [-8.8908e-01, -6.2573e-01, -6.2634e-01,  2.4850e+00, -3.1318e-01,\n",
      "          1.3475e+00, -3.3303e-01, -9.7261e-01,  5.5419e-01,  1.4172e-01],\n",
      "        [ 1.4813e+00, -2.0178e+00,  6.6729e-01, -1.3749e+00,  9.5703e-01,\n",
      "          1.4937e-01,  1.3973e+00, -9.4881e-01, -2.3780e-01, -3.2388e-01],\n",
      "        [-8.4332e-01, -1.7217e-01,  7.1223e-01, -1.8593e-01, -1.2387e-01,\n",
      "         -5.8799e-01, -1.4089e+00,  1.8719e+00,  7.5047e-01,  5.1382e-01],\n",
      "        [ 3.5566e-01, -1.1964e+00,  2.6093e+00,  1.6395e-01, -7.9899e-01,\n",
      "          3.2554e-01,  4.4557e-01, -3.6605e-01,  4.7822e-01, -1.6933e+00],\n",
      "        [-6.9544e-01, -1.5812e+00,  6.6067e-02, -1.4036e-01,  1.0878e-01,\n",
      "         -3.4941e-01, -5.5298e-01,  2.3075e+00, -7.9876e-02,  8.3793e-01],\n",
      "        [-1.4170e+00,  2.0660e+00, -3.6477e-01,  9.2879e-02, -6.6779e-01,\n",
      "          1.5687e-01, -1.8015e-02,  1.0017e-01,  3.7740e-01,  1.0042e-01],\n",
      "        [ 2.0135e-01,  6.3696e-01,  9.4019e-01,  1.2854e+00, -1.8895e+00,\n",
      "          3.5278e-01,  5.3962e-01, -1.3808e+00,  5.9487e-01, -1.4808e+00],\n",
      "        [-1.5651e+00,  2.9823e+00, -1.3695e-01,  2.0704e-01, -1.3782e+00,\n",
      "          2.6141e-02, -2.3932e-01, -4.6102e-01,  5.6928e-01, -1.2854e-01],\n",
      "        [-6.6362e-01,  1.6645e+00, -3.0155e-03, -8.7919e-02, -7.2751e-01,\n",
      "         -5.7209e-02, -5.3685e-02, -3.5971e-02,  1.4939e-01, -6.9201e-02],\n",
      "        [-8.9076e-01, -8.1286e-01, -2.9017e-01, -3.4077e-01,  1.5466e-01,\n",
      "         -6.7527e-02, -6.2178e-01,  2.1122e+00, -2.1155e-01,  1.1533e+00],\n",
      "        [-1.9432e+00, -4.9307e-01, -2.2301e-01, -4.7422e-01,  2.0176e+00,\n",
      "         -6.0128e-01, -8.0835e-01,  6.3460e-01,  3.2474e-01,  1.6040e+00],\n",
      "        [-4.4951e-01,  7.9622e-01,  1.1106e+00,  3.3767e-02, -1.9353e-01,\n",
      "         -2.2820e-01,  2.7908e-01, -1.1315e+00,  3.2622e-01, -5.9641e-01],\n",
      "        [-1.0359e+00,  1.9141e-01,  3.4832e-02,  1.4547e+00, -6.9729e-01,\n",
      "          5.5014e-01,  4.4135e-01, -1.7218e-01,  2.2259e-02, -1.1112e-01],\n",
      "        [ 2.3018e-01, -1.0885e+00, -3.6978e-01,  1.7901e+00, -3.4787e-01,\n",
      "          1.4142e+00,  1.9878e-01, -1.2619e+00,  9.4304e-01, -1.6234e-01],\n",
      "        [-1.4151e+00,  3.0981e-01, -1.6290e-01,  9.0678e-01, -8.9143e-02,\n",
      "          4.3537e-01,  1.1103e-01, -5.5253e-02,  1.8990e-01,  2.6291e-01],\n",
      "        [-7.2723e-01, -2.6610e-01,  1.6493e+00, -4.9334e-01,  3.0815e-01,\n",
      "         -6.3467e-01,  7.0560e-01, -2.5856e-01, -6.5981e-02,  2.5496e-02],\n",
      "        [-8.6031e-01, -2.7688e+00, -1.3624e+00, -1.3804e-01,  2.8985e+00,\n",
      "          3.6417e-01, -5.4520e-01,  2.9804e-01,  6.2376e-01,  2.2401e+00],\n",
      "        [-1.4823e-01, -1.9713e+00,  4.0012e-01, -7.7709e-01,  2.2712e+00,\n",
      "         -6.9386e-01,  2.5566e-01,  4.2284e-01, -1.6839e-01,  8.7194e-01],\n",
      "        [ 2.2364e-02, -1.0420e+00,  1.9180e-01,  3.2299e-01, -4.1238e-01,\n",
      "          6.8402e-01,  2.2322e+00, -1.0847e+00,  1.0017e-04, -3.3637e-01],\n",
      "        [ 1.4602e-02, -9.4739e-01, -2.6443e-01,  1.7327e+00, -6.2581e-01,\n",
      "          7.0296e-01, -1.0911e-01, -5.5461e-01,  5.3604e-02, -2.1480e-02],\n",
      "        [ 6.7639e-01, -1.2329e+00, -1.3168e+00,  1.4025e-01,  5.1725e-01,\n",
      "          1.4330e+00, -4.6271e-03, -2.3162e-01,  1.3265e-01,  4.6812e-01],\n",
      "        [ 2.6225e-01, -1.0437e+00, -5.2162e-01,  9.9470e-01, -1.9346e-01,\n",
      "          6.3562e-01, -1.6061e-01, -6.4694e-01,  4.0078e-01, -3.0580e-01],\n",
      "        [ 1.1822e-01, -3.9891e-01,  1.1426e+00, -3.5915e-01,  2.7908e-01,\n",
      "         -4.8329e-01,  6.9062e-01, -6.9532e-01, -1.7201e-01, -4.9605e-01],\n",
      "        [ 1.6188e+00, -2.2494e+00, -5.4251e-01,  6.9408e-01, -5.9997e-01,\n",
      "          1.0465e+00,  3.1050e-01, -7.8828e-01,  1.4148e+00, -3.5271e-01],\n",
      "        [ 3.1356e-01, -2.5705e+00, -1.7531e-01, -6.9477e-01,  2.6176e+00,\n",
      "          1.4106e-01,  3.7245e-01, -3.0979e-01, -2.4834e-01,  9.4079e-01],\n",
      "        [-1.0609e+00,  2.4526e+00,  2.1590e-02,  2.0564e-01, -9.6947e-01,\n",
      "         -2.9106e-01, -5.1411e-01, -1.5240e-01,  2.3932e-01, -9.3158e-02],\n",
      "        [-1.2848e-01, -1.8912e+00, -1.0221e+00, -1.0091e+00,  1.6710e+00,\n",
      "         -2.1961e-01,  9.7684e-02,  9.2779e-01, -1.9528e-01,  2.1347e+00],\n",
      "        [ 5.3831e-02,  9.7097e-02, -3.2677e-01, -3.6711e-01,  2.2898e-01,\n",
      "          2.4132e-01, -3.1801e-01,  4.4631e-01,  1.6555e-01, -2.1751e-01],\n",
      "        [-2.2570e-01, -1.5615e+00, -1.0401e+00,  5.7080e-01,  4.5773e-01,\n",
      "          5.9514e-02, -2.4969e-01,  1.9439e+00, -5.2443e-01,  4.6448e-01],\n",
      "        [ 3.7267e-01, -7.4974e-01,  1.0124e+00, -1.4626e+00, -2.8217e-02,\n",
      "          2.2220e-01,  6.4307e-01, -7.3779e-01,  1.2127e+00,  2.4623e-01],\n",
      "        [-8.9420e-01, -9.4331e-01, -3.6553e-02, -2.6091e-01,  7.1328e-01,\n",
      "          1.6625e-02,  1.6154e-01, -7.9020e-03,  4.3720e-01,  1.0162e+00],\n",
      "        [-7.6039e-01, -5.3055e-02,  1.4644e+00,  6.5831e-01,  9.0918e-02,\n",
      "         -1.8499e-01, -2.7053e-01, -6.4523e-01,  7.3011e-01,  1.6694e-01],\n",
      "        [-8.0046e-01, -8.5779e-01, -7.6709e-02, -7.2478e-01,  8.9178e-01,\n",
      "         -4.8451e-01, -6.0128e-01,  1.6671e+00,  2.4449e-01,  7.7678e-01],\n",
      "        [-1.1963e+00, -5.8899e-01, -3.5253e-01,  4.8562e-01,  5.8754e-01,\n",
      "          4.6095e-01,  1.1971e-01, -2.4943e-01,  5.1241e-01,  8.8837e-01],\n",
      "        [ 3.7171e-01, -2.6201e-01,  6.7431e-01, -4.0526e-01,  3.0795e-01,\n",
      "         -5.5816e-01,  5.0441e-01,  4.2774e-01, -4.2910e-01, -3.4499e-01],\n",
      "        [-4.9391e-01, -1.2616e+00,  4.7437e-01, -9.6649e-01,  2.0899e+00,\n",
      "         -7.9315e-01, -6.3755e-02,  5.8498e-01,  2.4315e-01,  7.1744e-01],\n",
      "        [-1.1170e+00, -3.7045e-01, -3.2413e-01,  2.7966e+00, -4.6531e-01,\n",
      "          8.8934e-01, -7.2754e-01, -7.6303e-01,  9.2798e-01,  3.3671e-02],\n",
      "        [ 2.4819e+00, -1.3395e+00,  3.5321e-01, -6.6833e-01, -1.2933e+00,\n",
      "          6.9424e-01,  5.1597e-01,  2.0395e-02, -3.5823e-01, -4.9278e-01],\n",
      "        [ 3.7463e-01, -1.4027e+00, -9.7136e-01, -6.5925e-02,  1.5787e-01,\n",
      "         -2.9777e-01, -1.0602e+00,  2.9769e+00, -2.7448e-01,  5.3749e-01],\n",
      "        [ 4.4192e+00, -2.8276e+00,  8.1500e-01,  3.4421e-01, -9.6340e-01,\n",
      "          1.0747e+00,  1.2955e-01, -1.2949e+00,  5.4186e-01, -1.5671e+00],\n",
      "        [ 1.5120e+00, -1.2348e+00,  1.7636e+00,  1.3296e+00, -8.9842e-01,\n",
      "          3.3706e-01,  4.4411e-01, -8.8875e-01,  1.4114e-01, -1.8132e+00],\n",
      "        [-1.3501e+00,  9.2844e-01,  3.6560e-01,  7.6342e-02, -8.3592e-01,\n",
      "         -4.1245e-01, -9.1557e-01,  6.8236e-01,  1.2731e+00,  4.8135e-01],\n",
      "        [-1.4334e+00,  2.4457e+00, -4.4347e-01,  5.0804e-03, -9.5418e-01,\n",
      "          2.3628e-01,  1.6138e-03, -4.1451e-02,  5.2580e-01, -2.5855e-02],\n",
      "        [-1.7775e+00,  5.7677e-01, -7.8679e-01, -6.5971e-01,  8.8906e-01,\n",
      "         -5.6988e-01, -6.5230e-01,  1.8821e+00,  4.3669e-01,  9.1066e-01],\n",
      "        [-3.6175e-01,  2.1444e-01, -1.2929e-01,  2.3236e+00, -9.9391e-01,\n",
      "          1.0095e+00, -4.0939e-01, -9.9433e-01,  5.6134e-01, -5.9197e-01],\n",
      "        [-9.1423e-01, -6.3623e-01,  6.8038e-01, -8.3025e-01, -3.7873e-02,\n",
      "         -4.2456e-01, -1.3810e-01,  1.8424e+00, -1.1929e-01,  4.9900e-01],\n",
      "        [-1.5724e+00,  1.0085e+00, -6.6181e-01,  2.4144e-01, -9.6536e-02,\n",
      "         -4.3808e-02, -4.3198e-01,  4.0427e-01,  1.0628e+00,  8.7176e-01],\n",
      "        [-5.8809e-01, -6.0301e-01, -5.9237e-01, -1.0642e+00,  9.0261e-02,\n",
      "         -4.4333e-01, -1.3666e+00,  3.5153e+00,  6.0606e-01,  9.8612e-01],\n",
      "        [-5.0483e-01, -1.6684e+00, -1.1020e+00, -2.0148e-01,  1.0160e+00,\n",
      "          4.5935e-01, -4.1159e-01,  1.3862e+00, -6.1640e-01,  1.7650e+00],\n",
      "        [-3.6821e-02, -1.8878e+00,  4.7532e-01, -4.9935e-01,  1.1946e-01,\n",
      "          3.7546e-01,  2.3741e+00, -5.4465e-01, -1.4715e-01,  2.6018e-01],\n",
      "        [-4.4210e-01, -1.2347e+00,  4.1311e+00,  1.4350e-01, -1.2744e-02,\n",
      "         -9.9915e-01,  9.0585e-01, -1.0840e+00,  6.0949e-01, -1.3159e+00],\n",
      "        [-6.3269e-01, -1.7775e+00, -7.1715e-01, -2.2796e-01,  7.4717e-01,\n",
      "          5.8036e-02, -9.4644e-01,  2.1082e+00, -2.9861e-01,  1.5848e+00],\n",
      "        [-7.0527e-01, -2.4315e-01, -4.8699e-01, -4.9493e-01,  4.4065e-01,\n",
      "          5.5432e-01, -6.0792e-01, -5.6206e-01,  9.2046e-01,  3.3125e-01],\n",
      "        [-6.1767e-01, -2.4119e+00, -7.2339e-01, -1.2180e-02,  2.7502e+00,\n",
      "          3.9185e-01, -1.0713e-01, -3.5504e-01,  2.7598e-01,  1.3692e+00],\n",
      "        [-1.9066e+00,  5.0286e-01, -2.8342e-01, -7.1172e-01, -1.6246e-01,\n",
      "         -7.3060e-01, -1.0602e+00,  3.0940e+00,  4.9074e-01,  1.0701e+00],\n",
      "        [-4.6129e-02, -1.2499e+00, -1.2337e+00,  1.8576e+00, -1.1329e-01,\n",
      "          1.3270e+00,  6.3150e-01, -5.7004e-01, -1.4176e-01,  1.8138e-01],\n",
      "        [-2.0574e-01, -2.1406e+00,  8.4586e-01, -1.1363e+00,  9.4266e-01,\n",
      "         -5.8417e-01,  2.6691e+00, -1.4671e-01, -3.8607e-01,  2.8630e-01],\n",
      "        [-1.5980e+00,  2.8644e+00,  3.3393e-01, -6.3152e-02, -8.8999e-01,\n",
      "         -2.5736e-01, -2.1521e-01, -3.2266e-01,  5.5008e-01, -4.4550e-01],\n",
      "        [ 4.2953e-01, -6.0542e-01, -4.5419e-02,  2.7193e+00, -9.7770e-01,\n",
      "          8.6010e-01, -1.2649e+00, -5.1016e-01,  8.5768e-01, -5.3664e-01],\n",
      "        [-1.0446e+00, -5.3658e-01,  3.5233e-01, -5.1882e-01,  5.7421e-01,\n",
      "         -7.3010e-02,  2.6325e+00, -1.2041e+00,  2.3593e-01,  2.6175e-01],\n",
      "        [-7.1411e-01,  1.1041e-01,  2.7875e-02, -4.6119e-01,  5.0971e-01,\n",
      "         -1.1308e-01, -3.1640e-02, -4.2032e-03,  7.6439e-01,  4.5976e-01],\n",
      "        [-9.3133e-01, -2.8489e-01, -4.6006e-01,  2.7025e+00, -1.2489e+00,\n",
      "          1.2035e+00, -1.1348e+00,  5.5687e-01,  6.9597e-01,  2.6943e-01],\n",
      "        [-2.1807e+00,  1.8700e+00, -1.6509e-01,  1.2400e-01, -5.7483e-01,\n",
      "          9.5813e-02,  3.1333e-01, -2.5274e-01,  8.8214e-01,  4.1591e-02],\n",
      "        [-8.0939e-01, -5.1653e-01, -3.5556e-01, -1.4182e+00,  2.0954e+00,\n",
      "         -5.7174e-01,  4.5986e-01,  1.9014e-02,  1.7594e-02,  1.2938e+00],\n",
      "        [-1.0138e+00,  4.9890e-01, -3.8643e-01,  4.0065e-01, -9.9014e-02,\n",
      "          3.8026e-01, -1.2211e-01,  8.4183e-02,  2.0406e-01,  3.6272e-01],\n",
      "        [-1.9452e+00,  1.3250e+00, -8.2107e-01,  4.9661e-02, -1.6160e-01,\n",
      "         -2.6679e-02, -1.1330e-01,  7.3165e-01,  1.8782e-01,  4.4964e-01],\n",
      "        [ 7.7106e-01, -1.3764e+00,  7.9658e-01, -7.5484e-01, -2.7020e-01,\n",
      "          6.0981e-01,  1.8915e+00, -1.1385e+00,  2.1190e-02, -6.2793e-01],\n",
      "        [-1.1048e+00, -1.6234e+00, -1.1070e-01, -5.9478e-01,  1.4813e+00,\n",
      "         -6.9737e-01, -3.1798e-01,  8.4389e-01, -9.9690e-03,  2.2220e+00]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    if iter_test==1:\n",
    "        print('Outputs')\n",
    "        print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs\n",
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    if iter_test==1:\n",
    "        print('Outputs')\n",
    "        print(outputs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs\n",
      "tensor([-0.3915, -1.0796, -0.4682, -0.3333,  0.1149, -0.2292, -1.3685,  2.8098,\n",
      "        -0.0696,  0.9826], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    if iter_test==1:\n",
    "        print('Outputs')\n",
    "        print(outputs[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    if iter_test==1:\n",
    "        print('Prediction')\n",
    "        print(predicted.size())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "tensor(7)\n",
      "Label Size\n",
      "torch.Size([100])\n",
      "Label for Image 0\n",
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    if iter_test==1:\n",
    "        print('Prediction')\n",
    "        print(predicted[0])\n",
    "        \n",
    "        print('Label Size')\n",
    "        print(labels.size())\n",
    "        \n",
    "        print('Label for Image 0')\n",
    "        print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "tensor(2)\n",
      "Label Size\n",
      "torch.Size([100])\n",
      "Label for Image 0\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    if iter_test==1:\n",
    "        print('Prediction')\n",
    "        print(predicted[1])\n",
    "        \n",
    "        print('Label Size')\n",
    "        print(labels.size())\n",
    "        \n",
    "        print('Label for Image 0')\n",
    "        print(labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(82)\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "     # Total number of lables\n",
    "    total += labels.size(0)\n",
    "\n",
    "    # Total correct predictions\n",
    "    correct += (predicted == labels).sum()\n",
    "                \n",
    "accuracy = 100 * correct / total\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Explaining .sum() python built-in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# correct += (predicted == labels).sum()\n",
    "\n",
    "a = np.ones((10))\n",
    "b = np.ones((10))\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "print(a==b)\n",
    "\n",
    "print((a==b).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = False\n",
    "\n",
    "if save_model is True:\n",
    "    torch.save(model.state_dict(), 'logistic_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
