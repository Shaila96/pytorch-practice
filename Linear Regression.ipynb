{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Regression Basics\n",
    "\n",
    "- y = ax+b\n",
    "- x independent and y dependent variable\n",
    "- a = slope, b = intersept\n",
    "- a = co-efficient, b = bias/intercept\n",
    "\n",
    "#### Goal of linear regression:\n",
    "- minimize the distance between the point and the line (y=ax+b)\n",
    "\n",
    "#### Note:\n",
    "- Parameters refer to \n",
    "    - co-efficients in Linear Regression\n",
    "    - weights in neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example go through the video 17. Linear Regression Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building Linear Regression Model\n",
    "\n",
    "#### 2.1 Example\n",
    "- Coefficient, a = 2\n",
    "- Bias/Intercept, b = 1\n",
    "- Equatio, y= 2x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch            ## for creating tensors\n",
    "import torch.nn as nn   ## for modeling\n",
    "\n",
    "from torch.autograd import Variable  ## make variable for enable gradients\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Building dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vals = [i for i in range(11)]\n",
    "x_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to numpy\n",
    "x_train = np.array(x_vals, dtype=np.float32)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORTANT: 2D arr required\n",
    "x_train = x_train.reshape(-1, 1)  # (reshape(-1, 1) means, the second dimension will be 1 and for -1 it will auto calculate the dimension. Check: https://stackoverflow.com/questions/18691084/what-does-1-mean-in-numpy-reshape)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### y = 2x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vals = [2*i+1 for i in x_vals]\n",
    "y_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 7.],\n",
       "       [ 9.],\n",
       "       [11.],\n",
       "       [13.],\n",
       "       [15.],\n",
       "       [17.],\n",
       "       [19.],\n",
       "       [21.]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array(y_vals, dtype=np.float32)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Building model\n",
    "\n",
    "###### Linear model\n",
    "- Equation: y= 2x + 1\n",
    "\n",
    "\n",
    "###### Forward\n",
    "- Example\n",
    "    - Input, x = 1\n",
    "    - Output, y<sup>^</sup> = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegressionModel, self).__init__() # inherit everything from nn.Module\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return(out)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate Model Class\n",
    "- input: [0, 1 .... 10]\n",
    "- expected output: [1, 3 ..... 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearRegressionModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-042255b781e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moutput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegressionModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'LinearRegressionModel' is not defined"
     ]
    }
   ],
   "source": [
    "input_dim = 1\n",
    "output_dim = 1\n",
    "\n",
    "model = LinearRegressionModel(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate Loss Class\n",
    "- MSE Loss: Mean Squared Error\n",
    "- 1/n(sum(y<sup>^</sup> - y)) --> check video or google for exact equation\n",
    "- Reason to use it for minimizing the distance between the point and the linear regression line\n",
    "\n",
    "\n",
    "#### Cost Function/Loss Function/Optimizer\n",
    "- A loss function tells us \"How Good\" our model is making predictions for a given set of parameters.\n",
    "\n",
    "#### Gradient Descent\n",
    "- An optimization algorithm used to get the minimum of the function, by iteratively moving to the direction of steepest descent by the negative of the gradient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate Optimizer Class\n",
    "\n",
    "###### simpler equation\n",
    "- parameters = parameters - learning_rate * parameters_gradients\n",
    "    - parameters: a and b in y=ax+b\n",
    "    - desired parameters: a=2 and b=1 in y=2x+1\n",
    "\n",
    "###### What is the purpose fo the optimizer class\n",
    "- Update the model's parameter at every iteration\n",
    "- So that, we can get a better model to do the predictions\n",
    "    \n",
    "    \n",
    "###### Need more clarification?\n",
    "- Check at 11.00 min of the 18.Linear Regression video\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01 # How fast we want the model to learn\n",
    "\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate) # SGD is method of optimization, you need to use appropriate one for the specific data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model\n",
    "- 1 epoch: going through the whole x_train data once\n",
    "    - 100 epochs:\n",
    "        - 100x mapping x_train = [0, 1....10]\n",
    "- Process\n",
    "    - Convert inputs/labels to variables\n",
    "    - Clear gradient buffets\n",
    "    - Get output given inputs\n",
    "    - Get loss\n",
    "    - Get gradients w.r.t. parameters\n",
    "    - Update parameters using gradients\n",
    "        - parameters = parameters - learning_rate * parameters_gradients\n",
    "    - REPEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 317.64117431640625\n",
      "epoch: 2, loss: 25.90899658203125\n",
      "epoch: 3, loss: 2.113327980041504\n",
      "epoch: 4, loss: 0.17238858342170715\n",
      "epoch: 5, loss: 0.014072440564632416\n",
      "epoch: 6, loss: 0.0011590584181249142\n",
      "epoch: 7, loss: 0.00010563599789747968\n",
      "epoch: 8, loss: 1.9572858946048655e-05\n",
      "epoch: 9, loss: 1.2428176887624431e-05\n",
      "epoch: 10, loss: 1.1726707271009218e-05\n",
      "epoch: 11, loss: 1.1547555004653987e-05\n",
      "epoch: 12, loss: 1.1415416338422801e-05\n",
      "epoch: 13, loss: 1.1287880624877289e-05\n",
      "epoch: 14, loss: 1.1162272130604833e-05\n",
      "epoch: 15, loss: 1.1038300726795569e-05\n",
      "epoch: 16, loss: 1.0914421181951184e-05\n",
      "epoch: 17, loss: 1.079242974810768e-05\n",
      "epoch: 18, loss: 1.0672162716218736e-05\n",
      "epoch: 19, loss: 1.0552580533840228e-05\n",
      "epoch: 20, loss: 1.0434920113766566e-05\n",
      "epoch: 21, loss: 1.0317841770302039e-05\n",
      "epoch: 22, loss: 1.0204078535025474e-05\n",
      "epoch: 23, loss: 1.00901052064728e-05\n",
      "epoch: 24, loss: 9.976291039492935e-06\n",
      "epoch: 25, loss: 9.865040738077369e-06\n",
      "epoch: 26, loss: 9.755302016856149e-06\n",
      "epoch: 27, loss: 9.646115358918905e-06\n",
      "epoch: 28, loss: 9.538912308926228e-06\n",
      "epoch: 29, loss: 9.432506885787006e-06\n",
      "epoch: 30, loss: 9.32691455091117e-06\n",
      "epoch: 31, loss: 9.222114385920577e-06\n",
      "epoch: 32, loss: 9.119693459069822e-06\n",
      "epoch: 33, loss: 9.018211130751297e-06\n",
      "epoch: 34, loss: 8.917432751331944e-06\n",
      "epoch: 35, loss: 8.818649803288281e-06\n",
      "epoch: 36, loss: 8.719687684788369e-06\n",
      "epoch: 37, loss: 8.622239874966908e-06\n",
      "epoch: 38, loss: 8.525438715878408e-06\n",
      "epoch: 39, loss: 8.429237823293079e-06\n",
      "epoch: 40, loss: 8.335810889548156e-06\n",
      "epoch: 41, loss: 8.242898729804438e-06\n",
      "epoch: 42, loss: 8.150698704412207e-06\n",
      "epoch: 43, loss: 8.061118933255784e-06\n",
      "epoch: 44, loss: 7.970636033860501e-06\n",
      "epoch: 45, loss: 7.882028512540273e-06\n",
      "epoch: 46, loss: 7.792968972353265e-06\n",
      "epoch: 47, loss: 7.706064934609458e-06\n",
      "epoch: 48, loss: 7.621208624186693e-06\n",
      "epoch: 49, loss: 7.534938504250022e-06\n",
      "epoch: 50, loss: 7.450717930623796e-06\n",
      "epoch: 51, loss: 7.3672285907377955e-06\n",
      "epoch: 52, loss: 7.2853958954510745e-06\n",
      "epoch: 53, loss: 7.204283519968158e-06\n",
      "epoch: 54, loss: 7.122666829673108e-06\n",
      "epoch: 55, loss: 7.043960522423731e-06\n",
      "epoch: 56, loss: 6.9660959525208455e-06\n",
      "epoch: 57, loss: 6.886933988425881e-06\n",
      "epoch: 58, loss: 6.810551894886885e-06\n",
      "epoch: 59, loss: 6.7335990934225265e-06\n",
      "epoch: 60, loss: 6.6587399487616494e-06\n",
      "epoch: 61, loss: 6.58398221276002e-06\n",
      "epoch: 62, loss: 6.51084019409609e-06\n",
      "epoch: 63, loss: 6.438209311454557e-06\n",
      "epoch: 64, loss: 6.366088200593367e-06\n",
      "epoch: 65, loss: 6.295270850387169e-06\n",
      "epoch: 66, loss: 6.225221568456618e-06\n",
      "epoch: 67, loss: 6.156069048302015e-06\n",
      "epoch: 68, loss: 6.086552730266703e-06\n",
      "epoch: 69, loss: 6.019115517119644e-06\n",
      "epoch: 70, loss: 5.951746061327867e-06\n",
      "epoch: 71, loss: 5.886103735974757e-06\n",
      "epoch: 72, loss: 5.819985290145269e-06\n",
      "epoch: 73, loss: 5.754549420089461e-06\n",
      "epoch: 74, loss: 5.690073976438725e-06\n",
      "epoch: 75, loss: 5.627151040243916e-06\n",
      "epoch: 76, loss: 5.564056209550472e-06\n",
      "epoch: 77, loss: 5.501701707544271e-06\n",
      "epoch: 78, loss: 5.440252152766334e-06\n",
      "epoch: 79, loss: 5.379819413064979e-06\n",
      "epoch: 80, loss: 5.320112450135639e-06\n",
      "epoch: 81, loss: 5.260388206806965e-06\n",
      "epoch: 82, loss: 5.201047315495089e-06\n",
      "epoch: 83, loss: 5.1437723413982894e-06\n",
      "epoch: 84, loss: 5.086076271254569e-06\n",
      "epoch: 85, loss: 5.029445219406625e-06\n",
      "epoch: 86, loss: 4.973411250830395e-06\n",
      "epoch: 87, loss: 4.9178238441527355e-06\n",
      "epoch: 88, loss: 4.862495643465081e-06\n",
      "epoch: 89, loss: 4.8080000851769e-06\n",
      "epoch: 90, loss: 4.753724624606548e-06\n",
      "epoch: 91, loss: 4.700195404439e-06\n",
      "epoch: 92, loss: 4.648427875508787e-06\n",
      "epoch: 93, loss: 4.596580311044818e-06\n",
      "epoch: 94, loss: 4.545323008642299e-06\n",
      "epoch: 95, loss: 4.495248049352085e-06\n",
      "epoch: 96, loss: 4.445043487066869e-06\n",
      "epoch: 97, loss: 4.395062205730937e-06\n",
      "epoch: 98, loss: 4.345850356912706e-06\n",
      "epoch: 99, loss: 4.297543455322739e-06\n",
      "epoch: 100, loss: 4.250202437106054e-06\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "     # Convert numpy array to torch Variable\n",
    "    inputs = Variable(torch.from_numpy(x_train))\n",
    "    labels = Variable(torch.from_numpy(y_train)) # actual/true output\n",
    "    \n",
    "    # Clear gradients w.r.t. parameters\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward to get output\n",
    "    # This output is based on the parameters we have\n",
    "    outputs = model(inputs) # predicted output\n",
    "    \n",
    "    # Calculate loss\n",
    "    # We need to know the loss to update the gradients\n",
    "    loss = criterion(outputs, labels) # scalar loss\n",
    "    \n",
    "    # Getting gradients w.r.t parameters\n",
    "    # Based on the scalar loss, we calculate the gradients (based on learning rate also)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Updating parameters\n",
    "    # From the loss and newly calculated gradients we get the parameters for next epoch\n",
    "    optimizer.step() \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##--------------------------------------------------------------------------\n",
    "    ## WHY ARE NOT WE CLEARING THE GRADIENTS AT THE END? WHY AT THE BEGINING??\n",
    "    ##--------------------------------------------------------------------------\n",
    "    ## Clear gradients w.r.t. parameters\n",
    "    ##  optimizer.zero_grad()\n",
    "    ##--------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('epoch: {}, loss: {}'.format(epoch+1, loss.data))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0038348],\n",
       "       [ 3.0032825],\n",
       "       [ 5.0027304],\n",
       "       [ 7.0021777],\n",
       "       [ 9.001626 ],\n",
       "       [11.001073 ],\n",
       "       [13.000521 ],\n",
       "       [14.999969 ],\n",
       "       [16.999416 ],\n",
       "       [18.998865 ],\n",
       "       [20.998312 ]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 7.],\n",
       "       [ 9.],\n",
       "       [11.],\n",
       "       [13.],\n",
       "       [15.],\n",
       "       [17.],\n",
       "       [19.],\n",
       "       [21.]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = 2x + 1\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clear figures\n",
    "plt.clf()\n",
    "\n",
    "# Get predictions\n",
    "predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
    "\n",
    "# Plot the true data\n",
    "plt.plot(x_train, y_train, 'go', label='True Data', alpha=0.5)\n",
    "\n",
    "# Plot the predicted data\n",
    "plt.plot(x_train, predicted, '--', label='Predictions', alpha=0.5)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the first 2 lines when you really want to save the model\n",
    "save_model = False\n",
    "if save_model is True:\n",
    "    # Saves only the parameters (a and b)\n",
    "    torch.save(model.state_dict(), 'linear_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the first 2 lines when you really want to load the model\n",
    "load_model = False\n",
    "if load_model is True:\n",
    "    model.load_state_dict(torch.load(linear_model.pkl))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
